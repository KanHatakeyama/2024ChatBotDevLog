template: #使わない
  #system: aa
  instruction: <start_of_turn>user\n
  #input: aa
  output: <end_of_turn>\n<start_of_turn>model\n



data:
   - name: kanhatakeyama/multiturn-conv-from-aozora-bunko
     preprocess:
       - name: apply_chat_template
         args:
           messages: messages
           add_system_message: false
     split:
       train: train[:25000]
       #train: train[:2500]
       eval: train[25000:]
   - name: kanhatakeyama/twitter-auto_reply
     preprocess:
       - name: apply_chat_template
         args:
           messages: messages
           add_system_message: false
     split:
       #train: 20240923initial[:10]
       train: 20240923initial[:7000000]
       eval: 20240923initial[7388000:]
   - name: kanhatakeyama/ramdom-to-fixed-multiturn-Calm3
     preprocess:
       - name: apply_chat_template
         args:
           messages: messages
           add_system_message: false
     split:
       #train: 20240806filtered[:10]
       train: 20240806filtered[:10000]
       eval: 20240806filtered[10000:10500]

model:
  #name: weblab-GENIAC/Tanuki-8B-dpo-v1.0
  name: AXCXEPT/EZO-Common-9B-gemma-2-it

tokenizer:
  name: null
  # name: team-hatakeyama-phase2/tanuki-tokenizer

exp_params:
  num_train_epochs: 1
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 512
  save_strategy: steps
  save_steps: 1000
  logging_steps: 1
  learning_rate: 1e-4
  warmup_ratio: 0.1
  lr_scheduler_type: cosine
  dtype: bf16
  use_fast: true
  gradient_checkpointing: true
  max_seq_length: 4096
  use_peft: true
  peft_target_model: llama
  use_flash_attention_2: true
  peft_lora_r: 256
  peft_lora_alpha: 512
  peft_lora_dropout: 0.05
  neftune_noise_alpha: null

  do_eval: true
  eval_strategy: steps
  eval_steps: 50